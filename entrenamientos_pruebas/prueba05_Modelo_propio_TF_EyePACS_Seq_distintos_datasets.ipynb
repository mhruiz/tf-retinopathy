{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "composed-prime",
   "metadata": {},
   "source": [
    "# Codigo propio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "theoretical-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.custom_metrics as metrics\n",
    "import lib.evaluation as ev\n",
    "import lib.plotting as plot\n",
    "import lib.models as models\n",
    "import lib.dataset as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collected-ivory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cognitive-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_LEVELS_PER_CLASS = [[0], [1,2,3,4]]\n",
    "\n",
    "IMAGE_SIZE = (540, 540, 3)\n",
    "\n",
    "# Specify dataset files\n",
    "TRAIN_FILE = 'DATASET-VALIDATION-10.csv'\n",
    "VALIDATION_FILE = 'DATASET-TEST-10.csv'\n",
    "\n",
    "TRAINING_BATCH_SIZE = 32\n",
    "TRAINING_DATA_AUG = False\n",
    "TRAINING_BALANCED = False\n",
    "TRAINING_SHUFFLE = False\n",
    "TRAINING_PREFETCH = None\n",
    "TRAINING_TAKE_SIZE = None\n",
    "\n",
    "VALIDATION_BATCH_SIZE = 32\n",
    "VALIDATION_DATA_AUG = False\n",
    "VALIDATION_BALANCED = False\n",
    "VALIDATION_SHUFFLE = False\n",
    "VALIDATION_PREFETCH = None\n",
    "VALIDATION_TAKE_SIZE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "genetic-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dt)\n",
    "\n",
    "'''\n",
    "def create_dataset_new(csv_file, \n",
    "                        list_list_classes,\n",
    "                        balanced=False,\n",
    "                        apply_data_augmentation=False,\n",
    "                        batch_size=1, \n",
    "                        prefetch_buffer=None, \n",
    "                        shuffle=False,\n",
    "                        size=None):\n",
    "'''\n",
    "\n",
    "train_dataset, y_true_train = dt.create_dataset_new(TRAIN_FILE, \n",
    "                                                    DR_LEVELS_PER_CLASS, \n",
    "                                                    balanced=TRAINING_BALANCED, \n",
    "                                                    apply_data_augmentation=TRAINING_DATA_AUG, \n",
    "                                                    batch_size=TRAINING_BATCH_SIZE, \n",
    "                                                    prefetch_buffer=TRAINING_PREFETCH, \n",
    "                                                    shuffle=TRAINING_SHUFFLE,\n",
    "                                                    size=TRAINING_TAKE_SIZE)\n",
    "\n",
    "val_dataset, y_true_val = dt.create_dataset_new(VALIDATION_FILE, \n",
    "                                                DR_LEVELS_PER_CLASS, \n",
    "                                                balanced=VALIDATION_BALANCED,\n",
    "                                                apply_data_augmentation=VALIDATION_DATA_AUG,\n",
    "                                                batch_size=VALIDATION_BATCH_SIZE,\n",
    "                                                prefetch_buffer=VALIDATION_PREFETCH, \n",
    "                                                shuffle=VALIDATION_SHUFFLE, \n",
    "                                                size=VALIDATION_TAKE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lesser-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(5,5), strides=2, input_shape=IMAGE_SIZE),\n",
    "    tf.keras.layers.ReLU(), # 270, 270\n",
    "    tf.keras.layers.Conv2D(32,(7,7), strides=5),\n",
    "    tf.keras.layers.ReLU(), # 54, 54\n",
    "    tf.keras.layers.Conv2D(32,(3,3), strides=2),\n",
    "    tf.keras.layers.ReLU(), # 27, 27\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(48, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(len(DR_LEVELS_PER_CLASS), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imposed-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "cbacks = [tf.keras.callbacks.TensorBoard('logs/EYEPACS_Seq_Modelo_propio 2', histogram_freq=1, write_graph=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "simple-fountain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2790), started 1 day, 0:39:08 ago. (Use '!kill 2790' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fd5838aabecdf49e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fd5838aabecdf49e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See Tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proved-spirituality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "222/222 [==============================] - 26s 118ms/step - loss: 0.5842 - accuracy: 0.7460 - val_loss: 0.5863 - val_accuracy: 0.7354\n",
      "Epoch 2/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5700 - accuracy: 0.7462 - val_loss: 0.5808 - val_accuracy: 0.7354\n",
      "Epoch 3/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5649 - accuracy: 0.7467 - val_loss: 0.5791 - val_accuracy: 0.7354\n",
      "Epoch 4/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5586 - accuracy: 0.7467 - val_loss: 0.5760 - val_accuracy: 0.7354\n",
      "Epoch 5/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.5569 - accuracy: 0.7467 - val_loss: 0.5750 - val_accuracy: 0.7354\n",
      "Epoch 6/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5553 - accuracy: 0.7467 - val_loss: 0.5759 - val_accuracy: 0.7354\n",
      "Epoch 7/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5539 - accuracy: 0.7467 - val_loss: 0.5720 - val_accuracy: 0.7354\n",
      "Epoch 8/50\n",
      "222/222 [==============================] - 26s 119ms/step - loss: 0.5497 - accuracy: 0.7466 - val_loss: 0.5699 - val_accuracy: 0.7354\n",
      "Epoch 9/50\n",
      "222/222 [==============================] - 26s 118ms/step - loss: 0.5489 - accuracy: 0.7467 - val_loss: 0.5720 - val_accuracy: 0.7354\n",
      "Epoch 10/50\n",
      "222/222 [==============================] - 25s 114ms/step - loss: 0.5467 - accuracy: 0.7463 - val_loss: 0.5719 - val_accuracy: 0.7354\n",
      "Epoch 11/50\n",
      "222/222 [==============================] - 25s 115ms/step - loss: 0.5428 - accuracy: 0.7467 - val_loss: 0.5712 - val_accuracy: 0.7354\n",
      "Epoch 12/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.5409 - accuracy: 0.7467 - val_loss: 0.5730 - val_accuracy: 0.7354\n",
      "Epoch 13/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5403 - accuracy: 0.7469 - val_loss: 0.5712 - val_accuracy: 0.7354\n",
      "Epoch 14/50\n",
      "222/222 [==============================] - 25s 114ms/step - loss: 0.5387 - accuracy: 0.7467 - val_loss: 0.5740 - val_accuracy: 0.7354\n",
      "Epoch 15/50\n",
      "222/222 [==============================] - 25s 114ms/step - loss: 0.5332 - accuracy: 0.7471 - val_loss: 0.5752 - val_accuracy: 0.7349\n",
      "Epoch 16/50\n",
      "222/222 [==============================] - 25s 114ms/step - loss: 0.5303 - accuracy: 0.7486 - val_loss: 0.5824 - val_accuracy: 0.7253\n",
      "Epoch 17/50\n",
      "222/222 [==============================] - 25s 114ms/step - loss: 0.5288 - accuracy: 0.7480 - val_loss: 0.5813 - val_accuracy: 0.7288\n",
      "Epoch 18/50\n",
      "222/222 [==============================] - 25s 115ms/step - loss: 0.5263 - accuracy: 0.7507 - val_loss: 0.5818 - val_accuracy: 0.7291\n",
      "Epoch 19/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5128 - accuracy: 0.7532 - val_loss: 0.5854 - val_accuracy: 0.7302\n",
      "Epoch 20/50\n",
      "222/222 [==============================] - 26s 119ms/step - loss: 0.5087 - accuracy: 0.7543 - val_loss: 0.5874 - val_accuracy: 0.7291\n",
      "Epoch 21/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.4984 - accuracy: 0.7577 - val_loss: 0.5972 - val_accuracy: 0.7215\n",
      "Epoch 22/50\n",
      "222/222 [==============================] - 26s 118ms/step - loss: 0.4790 - accuracy: 0.7642 - val_loss: 0.5950 - val_accuracy: 0.7357\n",
      "Epoch 23/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.4594 - accuracy: 0.7798 - val_loss: 0.6252 - val_accuracy: 0.7144\n",
      "Epoch 24/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.4286 - accuracy: 0.7949 - val_loss: 0.6481 - val_accuracy: 0.7022\n",
      "Epoch 25/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.3974 - accuracy: 0.8142 - val_loss: 0.6686 - val_accuracy: 0.7097\n",
      "Epoch 26/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.3675 - accuracy: 0.8236 - val_loss: 0.7323 - val_accuracy: 0.6925\n",
      "Epoch 27/50\n",
      "222/222 [==============================] - 26s 118ms/step - loss: 0.3233 - accuracy: 0.8482 - val_loss: 0.8358 - val_accuracy: 0.6770\n",
      "Epoch 28/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.3043 - accuracy: 0.8577 - val_loss: 0.9028 - val_accuracy: 0.6778\n",
      "Epoch 29/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.2855 - accuracy: 0.8663 - val_loss: 0.9320 - val_accuracy: 0.6952\n",
      "Epoch 30/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.2450 - accuracy: 0.8851 - val_loss: 0.9450 - val_accuracy: 0.6870\n",
      "Epoch 31/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.2297 - accuracy: 0.8906 - val_loss: 1.0292 - val_accuracy: 0.6811\n",
      "Epoch 32/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.2286 - accuracy: 0.8941 - val_loss: 1.0505 - val_accuracy: 0.6849\n",
      "Epoch 33/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.2060 - accuracy: 0.9068 - val_loss: 1.1230 - val_accuracy: 0.6740\n",
      "Epoch 34/50\n",
      "222/222 [==============================] - 26s 119ms/step - loss: 0.1966 - accuracy: 0.9179 - val_loss: 1.1246 - val_accuracy: 0.6766\n",
      "Epoch 35/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.2099 - accuracy: 0.9062 - val_loss: 1.2103 - val_accuracy: 0.6557\n",
      "Epoch 36/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.1949 - accuracy: 0.9171 - val_loss: 1.1470 - val_accuracy: 0.671249 - accura\n",
      "Epoch 37/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.1585 - accuracy: 0.9337 - val_loss: 1.2144 - val_accuracy: 0.6701\n",
      "Epoch 38/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.1479 - accuracy: 0.9355 - val_loss: 1.3008 - val_accuracy: 0.6709\n",
      "Epoch 39/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.1418 - accuracy: 0.9400 - val_loss: 1.3561 - val_accuracy: 0.6674\n",
      "Epoch 40/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.1325 - accuracy: 0.9423 - val_loss: 1.4768 - val_accuracy: 0.6649\n",
      "Epoch 41/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.1172 - accuracy: 0.9528 - val_loss: 1.5661 - val_accuracy: 0.6743\n",
      "Epoch 42/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.1155 - accuracy: 0.9521 - val_loss: 1.4982 - val_accuracy: 0.6543\n",
      "Epoch 43/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.1020 - accuracy: 0.9593 - val_loss: 1.7316 - val_accuracy: 0.6812\n",
      "Epoch 44/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.1048 - accuracy: 0.9564 - val_loss: 1.8294 - val_accuracy: 0.6797\n",
      "Epoch 45/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.1156 - accuracy: 0.9559 - val_loss: 1.6691 - val_accuracy: 0.6730\n",
      "Epoch 46/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.1055 - accuracy: 0.9589 - val_loss: 1.7849 - val_accuracy: 0.6654\n",
      "Epoch 47/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.0902 - accuracy: 0.9652 - val_loss: 1.7646 - val_accuracy: 0.6612\n",
      "Epoch 48/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.0913 - accuracy: 0.9631 - val_loss: 1.7653 - val_accuracy: 0.6791\n",
      "Epoch 49/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.0862 - accuracy: 0.9676 - val_loss: 1.8268 - val_accuracy: 0.6588\n",
      "Epoch 50/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.0824 - accuracy: 0.9687 - val_loss: 1.9780 - val_accuracy: 0.6615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f290d917e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=50, validation_data=val_dataset, verbose=1, callbacks=cbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit6c4dec2e42734bc298ce0c3bfcfccb75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
