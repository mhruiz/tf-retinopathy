{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "permanent-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulated-occasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecological-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_LEVELS_PER_CLASS = [[0], [1,2,3,4]]\n",
    "\n",
    "IMAGE_SIZE = (540, 540, 3)\n",
    "\n",
    "# Specify dataset files\n",
    "TRAIN_FILE = 'DATASET-VALIDATION-10.csv'\n",
    "VALIDATION_FILE = 'DATASET-VALIDATION-10.csv'\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recovered-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, label):\n",
    "    return tf.image.decode_png(tf.io.read_file(path)), label\n",
    "\n",
    "def normalize(img, label):\n",
    "    return tf.cast(img, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "induced-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(TRAIN_FILE)\n",
    "\n",
    "asignations = [-1 for i in DR_LEVELS_PER_CLASS for j in i] # [[0], [1], [2,3,4]] --> [-1, -1, -1, -1, -1]\n",
    "for i, class_ in enumerate(DR_LEVELS_PER_CLASS):\n",
    "    for dr_lvl in class_:\n",
    "        asignations[dr_lvl] = i\n",
    "            \n",
    "dr_lvls = [asignations[i] for i in train_csv['DR_level'].tolist()]\n",
    "\n",
    "# print(asignations)\n",
    "# print(dr_lvls[:20])\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((train_csv['path'].tolist(), dr_lvls))\n",
    "# print(train_csv['DR_level'].tolist()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faced-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.map(read_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mature-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "equipped-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bridal-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(5,5), strides=2, input_shape=IMAGE_SIZE),\n",
    "    tf.keras.layers.ReLU(), # 270, 270\n",
    "    tf.keras.layers.Conv2D(32,(7,7), strides=5),\n",
    "    tf.keras.layers.ReLU(), # 54, 54\n",
    "    tf.keras.layers.Conv2D(32,(3,3), strides=2),\n",
    "    tf.keras.layers.ReLU(), # 27, 27\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(48, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(len(DR_LEVELS_PER_CLASS), activation='softmax')\n",
    "])\n",
    "\n",
    "# COMO LA SALIDA ES DADA POR NUMEROS ENTEROS, SE UTILIZA SPARSE_CATEGORICAL_CROSSENTROPY\n",
    "# ------------\n",
    "# Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided as integers. \n",
    "# If you want to provide labels using one-hot representation, please use CategoricalCrossentropy loss. There should be # classes \n",
    "# floating point values per feature for y_pred and a single floating point value per feature for y_true.\n",
    "# ------------\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "finite-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "cbacks = [tf.keras.callbacks.TensorBoard('logs/Modelo_basico_EYEPACS_Seq', histogram_freq=1, write_graph=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "statistical-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2790), started 23:10:54 ago. (Use '!kill 2790' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d1a5412ed05c373\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d1a5412ed05c373\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See Tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hearing-scene",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/222 [..............................] - ETA: 0s - loss: 0.7567 - accuracy: 0.2812WARNING:tensorflow:From /home/alumno/miguel_herrera/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "222/222 [==============================] - 94s 426ms/step - loss: 0.5749 - accuracy: 0.7445 - val_loss: 0.5730 - val_accuracy: 0.7467\n",
      "Epoch 2/50\n",
      "222/222 [==============================] - 63s 283ms/step - loss: 0.5634 - accuracy: 0.7463 - val_loss: 0.5656 - val_accuracy: 0.7467\n",
      "Epoch 3/50\n",
      "222/222 [==============================] - 64s 287ms/step - loss: 0.5601 - accuracy: 0.7466 - val_loss: 0.5657 - val_accuracy: 0.7467\n",
      "Epoch 4/50\n",
      "222/222 [==============================] - 62s 281ms/step - loss: 0.5583 - accuracy: 0.7467 - val_loss: 0.5534 - val_accuracy: 0.7464\n",
      "Epoch 5/50\n",
      "222/222 [==============================] - 63s 283ms/step - loss: 0.5553 - accuracy: 0.7464 - val_loss: 0.5532 - val_accuracy: 0.7464\n",
      "Epoch 6/50\n",
      "222/222 [==============================] - 63s 284ms/step - loss: 0.5530 - accuracy: 0.7459 - val_loss: 0.5494 - val_accuracy: 0.7466\n",
      "Epoch 7/50\n",
      "222/222 [==============================] - 64s 286ms/step - loss: 0.5517 - accuracy: 0.7464 - val_loss: 0.5557 - val_accuracy: 0.7466\n",
      "Epoch 8/50\n",
      "222/222 [==============================] - 70s 316ms/step - loss: 0.5541 - accuracy: 0.7442 - val_loss: 0.5412 - val_accuracy: 0.7467\n",
      "Epoch 9/50\n",
      "222/222 [==============================] - 76s 342ms/step - loss: 0.5511 - accuracy: 0.7467 - val_loss: 0.5436 - val_accuracy: 0.7467\n",
      "Epoch 10/50\n",
      "222/222 [==============================] - 72s 322ms/step - loss: 0.5480 - accuracy: 0.7467 - val_loss: 0.5429 - val_accuracy: 0.7460\n",
      "Epoch 11/50\n",
      "222/222 [==============================] - 75s 337ms/step - loss: 0.5409 - accuracy: 0.7469 - val_loss: 0.5413 - val_accuracy: 0.7460\n",
      "Epoch 12/50\n",
      "222/222 [==============================] - 75s 337ms/step - loss: 0.5380 - accuracy: 0.7466 - val_loss: 0.5353 - val_accuracy: 0.7463\n",
      "Epoch 13/50\n",
      "222/222 [==============================] - 74s 332ms/step - loss: 0.5342 - accuracy: 0.7471 - val_loss: 0.5295 - val_accuracy: 0.7490\n",
      "Epoch 14/50\n",
      "222/222 [==============================] - 78s 349ms/step - loss: 0.5265 - accuracy: 0.7532 - val_loss: 0.5194 - val_accuracy: 0.7555\n",
      "Epoch 15/50\n",
      "222/222 [==============================] - 74s 332ms/step - loss: 0.5187 - accuracy: 0.7528 - val_loss: 0.5100 - val_accuracy: 0.7594\n",
      "Epoch 16/50\n",
      "222/222 [==============================] - 74s 335ms/step - loss: 0.5049 - accuracy: 0.7611 - val_loss: 0.4963 - val_accuracy: 0.7626\n",
      "Epoch 17/50\n",
      "222/222 [==============================] - 76s 341ms/step - loss: 0.4887 - accuracy: 0.7684 - val_loss: 0.4836 - val_accuracy: 0.7698\n",
      "Epoch 18/50\n",
      "222/222 [==============================] - 75s 338ms/step - loss: 0.4732 - accuracy: 0.7807 - val_loss: 0.4692 - val_accuracy: 0.7769\n",
      "Epoch 19/50\n",
      "222/222 [==============================] - 75s 338ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4539 - val_accuracy: 0.7849\n",
      "Epoch 20/50\n",
      "222/222 [==============================] - 72s 323ms/step - loss: 0.4336 - accuracy: 0.7988 - val_loss: 0.4440 - val_accuracy: 0.7864\n",
      "Epoch 21/50\n",
      "222/222 [==============================] - 70s 317ms/step - loss: 0.3935 - accuracy: 0.8171 - val_loss: 0.4228 - val_accuracy: 0.8021\n",
      "Epoch 22/50\n",
      "222/222 [==============================] - 73s 330ms/step - loss: 0.3550 - accuracy: 0.8363 - val_loss: 0.4202 - val_accuracy: 0.8097\n",
      "Epoch 23/50\n",
      "222/222 [==============================] - 70s 314ms/step - loss: 0.3540 - accuracy: 0.8381 - val_loss: 0.3697 - val_accuracy: 0.8285\n",
      "Epoch 24/50\n",
      "222/222 [==============================] - 71s 322ms/step - loss: 0.3203 - accuracy: 0.8525 - val_loss: 0.3559 - val_accuracy: 0.8389\n",
      "Epoch 25/50\n",
      "222/222 [==============================] - 71s 322ms/step - loss: 0.3017 - accuracy: 0.8637 - val_loss: 0.3422 - val_accuracy: 0.8510\n",
      "Epoch 26/50\n",
      "222/222 [==============================] - 70s 314ms/step - loss: 0.2853 - accuracy: 0.8706 - val_loss: 0.3242 - val_accuracy: 0.8568\n",
      "Epoch 27/50\n",
      "222/222 [==============================] - 74s 332ms/step - loss: 0.2766 - accuracy: 0.8758 - val_loss: 0.3310 - val_accuracy: 0.8550\n",
      "Epoch 28/50\n",
      "222/222 [==============================] - 75s 336ms/step - loss: 0.2490 - accuracy: 0.8893 - val_loss: 0.3353 - val_accuracy: 0.8539\n",
      "Epoch 29/50\n",
      "222/222 [==============================] - 77s 346ms/step - loss: 0.2506 - accuracy: 0.8864 - val_loss: 0.3531 - val_accuracy: 0.8429\n",
      "Epoch 30/50\n",
      "222/222 [==============================] - 77s 346ms/step - loss: 0.2282 - accuracy: 0.8968 - val_loss: 0.3264 - val_accuracy: 0.8523\n",
      "Epoch 31/50\n",
      "222/222 [==============================] - 71s 319ms/step - loss: 0.2005 - accuracy: 0.9141 - val_loss: 0.3066 - val_accuracy: 0.8692\n",
      "Epoch 32/50\n",
      "222/222 [==============================] - 73s 327ms/step - loss: 0.1841 - accuracy: 0.9213 - val_loss: 0.3124 - val_accuracy: 0.8661\n",
      "Epoch 33/50\n",
      "222/222 [==============================] - 73s 330ms/step - loss: 0.1766 - accuracy: 0.9213 - val_loss: 0.3163 - val_accuracy: 0.8563\n",
      "Epoch 34/50\n",
      "222/222 [==============================] - 75s 336ms/step - loss: 0.1661 - accuracy: 0.9272 - val_loss: 0.2995 - val_accuracy: 0.8774\n",
      "Epoch 35/50\n",
      "222/222 [==============================] - 72s 325ms/step - loss: 0.1545 - accuracy: 0.9359 - val_loss: 0.2823 - val_accuracy: 0.8774\n",
      "Epoch 36/50\n",
      "222/222 [==============================] - 74s 331ms/step - loss: 0.1572 - accuracy: 0.9343 - val_loss: 0.3114 - val_accuracy: 0.8620\n",
      "Epoch 37/50\n",
      "222/222 [==============================] - 73s 329ms/step - loss: 0.1288 - accuracy: 0.9488 - val_loss: 0.2543 - val_accuracy: 0.8941\n",
      "Epoch 38/50\n",
      "222/222 [==============================] - 75s 338ms/step - loss: 0.1353 - accuracy: 0.9448 - val_loss: 0.2795 - val_accuracy: 0.8979\n",
      "Epoch 39/50\n",
      "222/222 [==============================] - 72s 325ms/step - loss: 0.1315 - accuracy: 0.9482 - val_loss: 0.1925 - val_accuracy: 0.9230\n",
      "Epoch 40/50\n",
      "222/222 [==============================] - 75s 336ms/step - loss: 0.1137 - accuracy: 0.9554 - val_loss: 0.2928 - val_accuracy: 0.8913\n",
      "Epoch 41/50\n",
      "222/222 [==============================] - 76s 340ms/step - loss: 0.1125 - accuracy: 0.9616 - val_loss: 0.2644 - val_accuracy: 0.9055\n",
      "Epoch 42/50\n",
      "222/222 [==============================] - 73s 330ms/step - loss: 0.0990 - accuracy: 0.9630 - val_loss: 0.4056 - val_accuracy: 0.8848\n",
      "Epoch 43/50\n",
      "222/222 [==============================] - 76s 343ms/step - loss: 0.0950 - accuracy: 0.9658 - val_loss: 0.4416 - val_accuracy: 0.8770\n",
      "Epoch 44/50\n",
      "222/222 [==============================] - 75s 337ms/step - loss: 0.1097 - accuracy: 0.9617 - val_loss: 0.3385 - val_accuracy: 0.8972\n",
      "Epoch 45/50\n",
      "222/222 [==============================] - 77s 346ms/step - loss: 0.0806 - accuracy: 0.9714 - val_loss: 0.2395 - val_accuracy: 0.9265\n",
      "Epoch 46/50\n",
      "222/222 [==============================] - 77s 345ms/step - loss: 0.0634 - accuracy: 0.9796 - val_loss: 0.1811 - val_accuracy: 0.9413\n",
      "Epoch 47/50\n",
      "222/222 [==============================] - 75s 338ms/step - loss: 0.0653 - accuracy: 0.9772 - val_loss: 0.1567 - val_accuracy: 0.9490\n",
      "Epoch 48/50\n",
      "222/222 [==============================] - 77s 348ms/step - loss: 0.0647 - accuracy: 0.9793 - val_loss: 0.1680 - val_accuracy: 0.9459\n",
      "Epoch 49/50\n",
      "222/222 [==============================] - 75s 338ms/step - loss: 0.0494 - accuracy: 0.9841 - val_loss: 0.1955 - val_accuracy: 0.9404\n",
      "Epoch 50/50\n",
      "222/222 [==============================] - 74s 334ms/step - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.1648 - val_accuracy: 0.9481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b802499a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset_train, epochs=50, validation_data=dataset_train, verbose=1, callbacks=cbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-directory",
   "metadata": {},
   "source": [
    "# Modelo ajustado (usando 'one-hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infrared-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_2 = tf.data.Dataset.from_tensor_slices((train_csv['path'].tolist(), tf.keras.utils.to_categorical(dr_lvls, num_classes=len(DR_LEVELS_PER_CLASS))))\n",
    "\n",
    "dataset_train_2 = dataset_train_2.map(read_image)\n",
    "dataset_train_2 = dataset_train_2.map(normalize)\n",
    "dataset_train_2 = dataset_train_2.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "employed-editor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "cbacks = [tf.keras.callbacks.TensorBoard('logs/EYEPACS_Seq_Modelo_ajustado', histogram_freq=1, write_graph=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exterior-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(5,5), strides=2, input_shape=IMAGE_SIZE),\n",
    "    tf.keras.layers.ReLU(), # 270, 270\n",
    "    tf.keras.layers.Conv2D(32,(7,7), strides=5),\n",
    "    tf.keras.layers.ReLU(), # 54, 54\n",
    "    tf.keras.layers.Conv2D(32,(3,3), strides=2),\n",
    "    tf.keras.layers.ReLU(), # 27, 27\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(48, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(len(DR_LEVELS_PER_CLASS), activation='softmax')\n",
    "])\n",
    "\n",
    "model_2.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prospective-dublin",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/222 [..............................] - ETA: 0s - loss: 0.6665 - accuracy: 0.7188WARNING:tensorflow:From /home/alumno/miguel_herrera/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "222/222 [==============================] - 73s 328ms/step - loss: 0.5760 - accuracy: 0.7467 - val_loss: 0.5745 - val_accuracy: 0.7467\n",
      "Epoch 2/50\n",
      "222/222 [==============================] - 73s 329ms/step - loss: 0.5631 - accuracy: 0.7467 - val_loss: 0.5609 - val_accuracy: 0.7467\n",
      "Epoch 3/50\n",
      "222/222 [==============================] - 74s 334ms/step - loss: 0.5631 - accuracy: 0.7460 - val_loss: 0.5571 - val_accuracy: 0.7467\n",
      "Epoch 4/50\n",
      "222/222 [==============================] - 77s 348ms/step - loss: 0.5581 - accuracy: 0.7467 - val_loss: 0.5594 - val_accuracy: 0.7467\n",
      "Epoch 5/50\n",
      "222/222 [==============================] - 71s 322ms/step - loss: 0.5548 - accuracy: 0.7467 - val_loss: 0.5531 - val_accuracy: 0.7467\n",
      "Epoch 6/50\n",
      "222/222 [==============================] - 76s 342ms/step - loss: 0.5503 - accuracy: 0.7467 - val_loss: 0.5499 - val_accuracy: 0.7467\n",
      "Epoch 7/50\n",
      "222/222 [==============================] - 76s 344ms/step - loss: 0.5462 - accuracy: 0.7467 - val_loss: 0.5532 - val_accuracy: 0.7467\n",
      "Epoch 8/50\n",
      "222/222 [==============================] - 77s 346ms/step - loss: 0.5440 - accuracy: 0.7467 - val_loss: 0.5499 - val_accuracy: 0.7467\n",
      "Epoch 9/50\n",
      "222/222 [==============================] - 75s 339ms/step - loss: 0.5421 - accuracy: 0.7467 - val_loss: 0.5390 - val_accuracy: 0.7467\n",
      "Epoch 10/50\n",
      "222/222 [==============================] - 78s 350ms/step - loss: 0.5384 - accuracy: 0.7467 - val_loss: 0.5367 - val_accuracy: 0.7467\n",
      "Epoch 11/50\n",
      "222/222 [==============================] - 72s 323ms/step - loss: 0.5374 - accuracy: 0.7467 - val_loss: 0.5319 - val_accuracy: 0.7469\n",
      "Epoch 12/50\n",
      "222/222 [==============================] - 76s 342ms/step - loss: 0.5329 - accuracy: 0.7467 - val_loss: 0.5258 - val_accuracy: 0.7469\n",
      "Epoch 13/50\n",
      "222/222 [==============================] - 69s 311ms/step - loss: 0.5255 - accuracy: 0.7469 - val_loss: 0.5222 - val_accuracy: 0.7469\n",
      "Epoch 14/50\n",
      "222/222 [==============================] - 76s 341ms/step - loss: 0.5221 - accuracy: 0.7469 - val_loss: 0.5215 - val_accuracy: 0.7469\n",
      "Epoch 15/50\n",
      "222/222 [==============================] - 77s 348ms/step - loss: 0.5095 - accuracy: 0.7484 - val_loss: 0.5149 - val_accuracy: 0.7487\n",
      "Epoch 16/50\n",
      "222/222 [==============================] - 76s 344ms/step - loss: 0.5048 - accuracy: 0.7542 - val_loss: 0.5295 - val_accuracy: 0.7514\n",
      "Epoch 17/50\n",
      "222/222 [==============================] - 76s 341ms/step - loss: 0.5048 - accuracy: 0.7569 - val_loss: 0.5145 - val_accuracy: 0.7600\n",
      "Epoch 18/50\n",
      "222/222 [==============================] - 77s 349ms/step - loss: 0.4903 - accuracy: 0.7635 - val_loss: 0.5076 - val_accuracy: 0.7653\n",
      "Epoch 19/50\n",
      "222/222 [==============================] - 73s 331ms/step - loss: 0.4781 - accuracy: 0.7721 - val_loss: 0.5155 - val_accuracy: 0.7576\n",
      "Epoch 20/50\n",
      "222/222 [==============================] - 77s 348ms/step - loss: 0.4617 - accuracy: 0.7816 - val_loss: 0.5766 - val_accuracy: 0.7181\n",
      "Epoch 21/50\n",
      "222/222 [==============================] - 78s 351ms/step - loss: 0.4499 - accuracy: 0.7876 - val_loss: 0.5148 - val_accuracy: 0.7383\n",
      "Epoch 22/50\n",
      "222/222 [==============================] - 75s 339ms/step - loss: 0.4173 - accuracy: 0.8057 - val_loss: 0.5936 - val_accuracy: 0.6839\n",
      "Epoch 23/50\n",
      "222/222 [==============================] - 78s 353ms/step - loss: 0.3884 - accuracy: 0.8254 - val_loss: 0.5750 - val_accuracy: 0.7167\n",
      "Epoch 24/50\n",
      "222/222 [==============================] - 76s 343ms/step - loss: 0.3679 - accuracy: 0.8353 - val_loss: 0.5267 - val_accuracy: 0.7562\n",
      "Epoch 25/50\n",
      "222/222 [==============================] - 78s 349ms/step - loss: 0.3489 - accuracy: 0.8457 - val_loss: 0.4809 - val_accuracy: 0.7749\n",
      "Epoch 26/50\n",
      "222/222 [==============================] - 77s 348ms/step - loss: 0.3375 - accuracy: 0.8509 - val_loss: 0.4580 - val_accuracy: 0.7876\n",
      "Epoch 27/50\n",
      "222/222 [==============================] - 76s 343ms/step - loss: 0.3289 - accuracy: 0.8556 - val_loss: 0.4440 - val_accuracy: 0.7959\n",
      "Epoch 28/50\n",
      "222/222 [==============================] - 76s 341ms/step - loss: 0.2962 - accuracy: 0.8744 - val_loss: 0.4160 - val_accuracy: 0.8068\n",
      "Epoch 29/50\n",
      "222/222 [==============================] - 77s 345ms/step - loss: 0.2868 - accuracy: 0.8768 - val_loss: 0.3679 - val_accuracy: 0.8340\n",
      "Epoch 30/50\n",
      "222/222 [==============================] - 80s 359ms/step - loss: 0.2746 - accuracy: 0.8868 - val_loss: 0.3690 - val_accuracy: 0.8356\n",
      "Epoch 31/50\n",
      "222/222 [==============================] - 76s 344ms/step - loss: 0.2280 - accuracy: 0.9012 - val_loss: 0.3657 - val_accuracy: 0.8416\n",
      "Epoch 32/50\n",
      "222/222 [==============================] - 76s 344ms/step - loss: 0.2011 - accuracy: 0.9155 - val_loss: 0.3609 - val_accuracy: 0.8547\n",
      "Epoch 33/50\n",
      "222/222 [==============================] - 75s 339ms/step - loss: 0.2122 - accuracy: 0.9158 - val_loss: 0.3898 - val_accuracy: 0.8225\n",
      "Epoch 34/50\n",
      "222/222 [==============================] - 78s 349ms/step - loss: 0.2121 - accuracy: 0.9114 - val_loss: 0.3088 - val_accuracy: 0.8705\n",
      "Epoch 35/50\n",
      "222/222 [==============================] - 76s 341ms/step - loss: 0.1805 - accuracy: 0.9261 - val_loss: 0.3338 - val_accuracy: 0.8692\n",
      "Epoch 36/50\n",
      "222/222 [==============================] - 76s 344ms/step - loss: 0.1624 - accuracy: 0.9344 - val_loss: 0.3210 - val_accuracy: 0.8655\n",
      "Epoch 37/50\n",
      "222/222 [==============================] - 75s 340ms/step - loss: 0.1519 - accuracy: 0.9434 - val_loss: 0.3549 - val_accuracy: 0.8544\n",
      "Epoch 38/50\n",
      "222/222 [==============================] - 76s 341ms/step - loss: 0.1273 - accuracy: 0.9533 - val_loss: 0.3463 - val_accuracy: 0.8570\n",
      "Epoch 39/50\n",
      "222/222 [==============================] - 77s 347ms/step - loss: 0.1058 - accuracy: 0.9604 - val_loss: 0.3075 - val_accuracy: 0.8719\n",
      "Epoch 40/50\n",
      "222/222 [==============================] - 78s 350ms/step - loss: 0.0944 - accuracy: 0.9641 - val_loss: 0.2793 - val_accuracy: 0.8864\n",
      "Epoch 41/50\n",
      "222/222 [==============================] - 77s 345ms/step - loss: 0.0851 - accuracy: 0.9678 - val_loss: 0.2466 - val_accuracy: 0.9044\n",
      "Epoch 42/50\n",
      "222/222 [==============================] - 78s 350ms/step - loss: 0.0778 - accuracy: 0.9745 - val_loss: 0.1391 - val_accuracy: 0.9489\n",
      "Epoch 43/50\n",
      "222/222 [==============================] - 78s 353ms/step - loss: 0.0599 - accuracy: 0.9785 - val_loss: 0.1460 - val_accuracy: 0.9500\n",
      "Epoch 44/50\n",
      "222/222 [==============================] - 77s 345ms/step - loss: 0.0661 - accuracy: 0.9762 - val_loss: 0.1404 - val_accuracy: 0.9457\n",
      "Epoch 45/50\n",
      "222/222 [==============================] - 78s 351ms/step - loss: 0.0587 - accuracy: 0.9800 - val_loss: 0.0901 - val_accuracy: 0.9689\n",
      "Epoch 46/50\n",
      "222/222 [==============================] - 75s 339ms/step - loss: 0.0349 - accuracy: 0.9892 - val_loss: 0.0698 - val_accuracy: 0.9779\n",
      "Epoch 47/50\n",
      "222/222 [==============================] - 76s 343ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.0747 - val_accuracy: 0.9751\n",
      "Epoch 48/50\n",
      "222/222 [==============================] - 77s 348ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.0853 - val_accuracy: 0.9737\n",
      "Epoch 49/50\n",
      "222/222 [==============================] - 73s 330ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0929 - val_accuracy: 0.9723\n",
      "Epoch 50/50\n",
      "222/222 [==============================] - 77s 349ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.1057 - val_accuracy: 0.9668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8fc86f6ac0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(dataset_train_2, epochs=50, validation_data=dataset_train_2, verbose=1, callbacks=cbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit6c4dec2e42734bc298ce0c3bfcfccb75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
