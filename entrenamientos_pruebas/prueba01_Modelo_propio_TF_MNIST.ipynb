{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "changing-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/quickstart/beginner?hl=es-419\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "angry-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitted-arabic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-average",
   "metadata": {},
   "source": [
    "# Guardar MNIST en disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geographic-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar im√°genes en disco y crear csvs para tener las mismas condiciones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "data_path = 'MNIST_dataset/'\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "\n",
    "    num_images = 0\n",
    "    for i in range(x_train.shape[0]):\n",
    "        paths.append(data_path + str(num_images).zfill(5) + '.png')\n",
    "        labels.append(int(y_train[i]))\n",
    "\n",
    "        cv2.imwrite(data_path + str(num_images).zfill(5) + '.png', x_train[i,...])\n",
    "        num_images += 1\n",
    "\n",
    "    csv = pd.DataFrame({\n",
    "        'path': paths,\n",
    "        'DR_level': labels\n",
    "    })\n",
    "    csv.to_csv('MNIST_train.csv', index=False)\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(x_test.shape[0]):\n",
    "        paths.append(data_path + str(num_images).zfill(5) + '.png')\n",
    "        labels.append(int(y_test[i]))\n",
    "\n",
    "        cv2.imwrite(data_path + str(num_images).zfill(5) + '.png', x_test[i,...])\n",
    "        num_images += 1\n",
    "\n",
    "    csv = pd.DataFrame({\n",
    "        'path': paths,\n",
    "        'DR_level': labels\n",
    "    })\n",
    "    csv.to_csv('MNIST_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "color-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar datasets descargados de memoria\n",
    "del x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-witch",
   "metadata": {},
   "source": [
    "# Codigo propio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.custom_metrics as metrics\n",
    "import lib.evaluation as ev\n",
    "import lib.plotting as plot\n",
    "import lib.models as models\n",
    "import lib.dataset as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "little-holiday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "municipal-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_LEVELS_PER_CLASS = [[i] for i in range(10)]\n",
    "\n",
    "# Specify dataset files\n",
    "TRAIN_FILE = 'MNIST_train.csv'\n",
    "VALIDATION_FILE = 'MNIST_val.csv'\n",
    "\n",
    "TRAINING_BATCH_SIZE = 32\n",
    "TRAINING_DATA_AUG = False\n",
    "TRAINING_BALANCED = False\n",
    "TRAINING_SHUFFLE = False\n",
    "TRAINING_PREFETCH = None\n",
    "TRAINING_TAKE_SIZE = None\n",
    "\n",
    "VALIDATION_BATCH_SIZE = 32\n",
    "VALIDATION_DATA_AUG = False\n",
    "VALIDATION_BALANCED = False\n",
    "VALIDATION_SHUFFLE = False\n",
    "VALIDATION_PREFETCH = None\n",
    "VALIDATION_TAKE_SIZE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "plastic-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dt)\n",
    "\n",
    "'''\n",
    "def create_dataset_new(csv_file, \n",
    "                        list_list_classes,\n",
    "                        balanced=False,\n",
    "                        apply_data_augmentation=False,\n",
    "                        batch_size=1, \n",
    "                        prefetch_buffer=None, \n",
    "                        shuffle=False,\n",
    "                        size=None):\n",
    "'''\n",
    "\n",
    "train_dataset, y_true_train = dt.create_dataset_new(TRAIN_FILE, \n",
    "                                                    DR_LEVELS_PER_CLASS, \n",
    "                                                    balanced=TRAINING_BALANCED, \n",
    "                                                    apply_data_augmentation=TRAINING_DATA_AUG, \n",
    "                                                    batch_size=TRAINING_BATCH_SIZE, \n",
    "                                                    prefetch_buffer=TRAINING_PREFETCH, \n",
    "                                                    shuffle=TRAINING_SHUFFLE,\n",
    "                                                    size=TRAINING_TAKE_SIZE)\n",
    "\n",
    "val_dataset, y_true_val = dt.create_dataset_new(VALIDATION_FILE, \n",
    "                                                DR_LEVELS_PER_CLASS, \n",
    "                                                balanced=VALIDATION_BALANCED,\n",
    "                                                apply_data_augmentation=VALIDATION_DATA_AUG,\n",
    "                                                batch_size=VALIDATION_BATCH_SIZE,\n",
    "                                                prefetch_buffer=VALIDATION_PREFETCH, \n",
    "                                                shuffle=VALIDATION_SHUFFLE, \n",
    "                                                size=VALIDATION_TAKE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "under-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 3)\n",
      "(32, 10)\n",
      "----\n",
      "(32, 28, 28, 3)\n",
      "(32, 10)\n",
      "----\n",
      "(32, 28, 28, 3)\n",
      "(32, 10)\n",
      "----\n",
      "(32, 28, 28, 3)\n",
      "(32, 10)\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for img, lb in train_dataset.take(4):\n",
    "    print(img.shape)\n",
    "    print(lb.shape)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cognitive-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28, 3)),\n",
    "  tf.keras.layers.Dense(48, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "headed-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "cbacks = [tf.keras.callbacks.TensorBoard('logs/MNIST_codigo_propio', histogram_freq=1, write_graph=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unique-poultry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 47036), started 2:21:41 ago. (Use '!kill 47036' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4e23f143f285d964\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4e23f143f285d964\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See Tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "broad-envelope",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.3118 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 0.0217s). Check your callbacks.\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3838 - accuracy: 0.8845 - val_loss: 0.1800 - val_accuracy: 0.9471\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2488 - accuracy: 0.9261 - val_loss: 0.1460 - val_accuracy: 0.9565\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2117 - accuracy: 0.9352 - val_loss: 0.1374 - val_accuracy: 0.9594\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1922 - accuracy: 0.9416 - val_loss: 0.1209 - val_accuracy: 0.9660\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1789 - accuracy: 0.9451 - val_loss: 0.1253 - val_accuracy: 0.9638\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1717 - accuracy: 0.9471 - val_loss: 0.1164 - val_accuracy: 0.9675\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1586 - accuracy: 0.9496 - val_loss: 0.1123 - val_accuracy: 0.9687\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1533 - accuracy: 0.9518 - val_loss: 0.1152 - val_accuracy: 0.9683\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1479 - accuracy: 0.9531 - val_loss: 0.1082 - val_accuracy: 0.9696\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1453 - accuracy: 0.9532 - val_loss: 0.1185 - val_accuracy: 0.9678\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1374 - accuracy: 0.9560 - val_loss: 0.1080 - val_accuracy: 0.9710\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1367 - accuracy: 0.9566 - val_loss: 0.1050 - val_accuracy: 0.9722\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1335 - accuracy: 0.9576 - val_loss: 0.1134 - val_accuracy: 0.9710\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1309 - accuracy: 0.9577 - val_loss: 0.1126 - val_accuracy: 0.9705\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1271 - accuracy: 0.9596 - val_loss: 0.1126 - val_accuracy: 0.9707\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1256 - accuracy: 0.9597 - val_loss: 0.1222 - val_accuracy: 0.9707\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1214 - accuracy: 0.9603 - val_loss: 0.1133 - val_accuracy: 0.9721\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1230 - accuracy: 0.9604 - val_loss: 0.1175 - val_accuracy: 0.9704\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1178 - accuracy: 0.9624 - val_loss: 0.1136 - val_accuracy: 0.9708\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1161 - accuracy: 0.9620 - val_loss: 0.1068 - val_accuracy: 0.9729\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1164 - accuracy: 0.9609 - val_loss: 0.1115 - val_accuracy: 0.9707\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1174 - accuracy: 0.9624 - val_loss: 0.1104 - val_accuracy: 0.9724\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1159 - accuracy: 0.9627 - val_loss: 0.1143 - val_accuracy: 0.9709\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1085 - accuracy: 0.9647 - val_loss: 0.1221 - val_accuracy: 0.9697\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1092 - accuracy: 0.9639 - val_loss: 0.1137 - val_accuracy: 0.9717\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1074 - accuracy: 0.9649 - val_loss: 0.1173 - val_accuracy: 0.9712\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1073 - accuracy: 0.9642 - val_loss: 0.1253 - val_accuracy: 0.9716\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1108 - accuracy: 0.9639 - val_loss: 0.1185 - val_accuracy: 0.9713\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1064 - accuracy: 0.9649 - val_loss: 0.1270 - val_accuracy: 0.9710\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1034 - accuracy: 0.9659 - val_loss: 0.1295 - val_accuracy: 0.9717\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1047 - accuracy: 0.9653 - val_loss: 0.1335 - val_accuracy: 0.9691\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1020 - accuracy: 0.9663 - val_loss: 0.1223 - val_accuracy: 0.9710\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1021 - accuracy: 0.9667 - val_loss: 0.1257 - val_accuracy: 0.9711\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1022 - accuracy: 0.9666 - val_loss: 0.1359 - val_accuracy: 0.9680\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1016 - accuracy: 0.9661 - val_loss: 0.1349 - val_accuracy: 0.9691\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1009 - accuracy: 0.9669 - val_loss: 0.1326 - val_accuracy: 0.9693\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0964 - accuracy: 0.9676 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0987 - accuracy: 0.9676 - val_loss: 0.1382 - val_accuracy: 0.9699\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0990 - accuracy: 0.9669 - val_loss: 0.1326 - val_accuracy: 0.9704\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0962 - accuracy: 0.9676 - val_loss: 0.1340 - val_accuracy: 0.9696\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0965 - accuracy: 0.9683 - val_loss: 0.1366 - val_accuracy: 0.9701\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0930 - accuracy: 0.9694 - val_loss: 0.1355 - val_accuracy: 0.9704\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0955 - accuracy: 0.9683 - val_loss: 0.1442 - val_accuracy: 0.9676\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0958 - accuracy: 0.9687 - val_loss: 0.1374 - val_accuracy: 0.9718\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0952 - accuracy: 0.9682 - val_loss: 0.1443 - val_accuracy: 0.9710\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0914 - accuracy: 0.9695 - val_loss: 0.1408 - val_accuracy: 0.9690\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0931 - accuracy: 0.9695 - val_loss: 0.1386 - val_accuracy: 0.9703\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0934 - accuracy: 0.9682 - val_loss: 0.1414 - val_accuracy: 0.9693\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0945 - accuracy: 0.9690 - val_loss: 0.1459 - val_accuracy: 0.9701\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0929 - accuracy: 0.9687 - val_loss: 0.1434 - val_accuracy: 0.9676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a6c2778e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=50, validation_data=val_dataset, verbose=1, callbacks=cbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit6c4dec2e42734bc298ce0c3bfcfccb75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
