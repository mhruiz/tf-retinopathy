{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "antique-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/quickstart/beginner?hl=es-419\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sought-capture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "united-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "soviet-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos de train: 60000\n",
      "Elementos de validacion: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Elementos de train:', x_train.shape[0])\n",
    "print('Elementos de validacion:', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "temporal-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(48, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "precious-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "cbacks = [tf.keras.callbacks.TensorBoard('logs/MNIST', histogram_freq=1, write_graph=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sealed-wesley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 47036), started 2:24:51 ago. (Use '!kill 47036' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c12a85bf2a4a876a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c12a85bf2a4a876a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See Tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cooked-membrane",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.4165 - accuracy: 0.0625WARNING:tensorflow:From /home/alumno/miguel_herrera/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0042s vs `on_train_batch_end` time: 0.0101s). Check your callbacks.\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4290 - accuracy: 0.8750 - val_loss: 0.1920 - val_accuracy: 0.9443\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 2s 935us/step - loss: 0.2434 - accuracy: 0.9285 - val_loss: 0.1545 - val_accuracy: 0.9531\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 2s 921us/step - loss: 0.2032 - accuracy: 0.9396 - val_loss: 0.1299 - val_accuracy: 0.9625\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 2s 913us/step - loss: 0.1815 - accuracy: 0.9444 - val_loss: 0.1201 - val_accuracy: 0.9637\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1673 - accuracy: 0.9487 - val_loss: 0.1213 - val_accuracy: 0.9654\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 2s 977us/step - loss: 0.1553 - accuracy: 0.9523 - val_loss: 0.1039 - val_accuracy: 0.9694\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1475 - accuracy: 0.9545 - val_loss: 0.1083 - val_accuracy: 0.9660\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 2s 953us/step - loss: 0.1427 - accuracy: 0.9553 - val_loss: 0.0989 - val_accuracy: 0.9703\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 2s 945us/step - loss: 0.1354 - accuracy: 0.9572 - val_loss: 0.1006 - val_accuracy: 0.9701\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 2s 956us/step - loss: 0.1336 - accuracy: 0.9587 - val_loss: 0.0992 - val_accuracy: 0.9690\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 2s 949us/step - loss: 0.1271 - accuracy: 0.9594 - val_loss: 0.0988 - val_accuracy: 0.9705\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 2s 957us/step - loss: 0.1240 - accuracy: 0.9615 - val_loss: 0.0973 - val_accuracy: 0.9720\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 2s 972us/step - loss: 0.1204 - accuracy: 0.9611 - val_loss: 0.0930 - val_accuracy: 0.9738\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 2s 996us/step - loss: 0.1187 - accuracy: 0.9617 - val_loss: 0.0993 - val_accuracy: 0.9725\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 2s 960us/step - loss: 0.1151 - accuracy: 0.9633 - val_loss: 0.0968 - val_accuracy: 0.9715\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 2s 986us/step - loss: 0.1132 - accuracy: 0.9635 - val_loss: 0.0972 - val_accuracy: 0.9717\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 2s 977us/step - loss: 0.1092 - accuracy: 0.9643 - val_loss: 0.0965 - val_accuracy: 0.9708\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 2s 977us/step - loss: 0.1083 - accuracy: 0.9649 - val_loss: 0.0990 - val_accuracy: 0.9721\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1060 - accuracy: 0.9656 - val_loss: 0.0980 - val_accuracy: 0.9719\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 2s 902us/step - loss: 0.1045 - accuracy: 0.9654 - val_loss: 0.0980 - val_accuracy: 0.9722\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 2s 919us/step - loss: 0.1005 - accuracy: 0.9680 - val_loss: 0.1005 - val_accuracy: 0.9711\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 2s 899us/step - loss: 0.1020 - accuracy: 0.9659 - val_loss: 0.0990 - val_accuracy: 0.9726\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 2s 912us/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 0.0972 - val_accuracy: 0.9740\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 2s 932us/step - loss: 0.0963 - accuracy: 0.9672 - val_loss: 0.1029 - val_accuracy: 0.9714\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 2s 930us/step - loss: 0.0977 - accuracy: 0.9680 - val_loss: 0.1012 - val_accuracy: 0.9730\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 2s 915us/step - loss: 0.0937 - accuracy: 0.9687 - val_loss: 0.1024 - val_accuracy: 0.9723\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 2s 921us/step - loss: 0.0964 - accuracy: 0.9689 - val_loss: 0.1044 - val_accuracy: 0.9715\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 2s 947us/step - loss: 0.0956 - accuracy: 0.9680 - val_loss: 0.1032 - val_accuracy: 0.9740\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 2s 910us/step - loss: 0.0933 - accuracy: 0.9688 - val_loss: 0.1038 - val_accuracy: 0.9735\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 2s 914us/step - loss: 0.0913 - accuracy: 0.9699 - val_loss: 0.1098 - val_accuracy: 0.9716\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 2s 951us/step - loss: 0.0878 - accuracy: 0.9712 - val_loss: 0.1047 - val_accuracy: 0.9728\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 2s 948us/step - loss: 0.0902 - accuracy: 0.9697 - val_loss: 0.1070 - val_accuracy: 0.9724\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0884 - accuracy: 0.9702 - val_loss: 0.1049 - val_accuracy: 0.9733\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 2s 949us/step - loss: 0.0864 - accuracy: 0.9712 - val_loss: 0.1063 - val_accuracy: 0.9711\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0849 - accuracy: 0.9715 - val_loss: 0.1055 - val_accuracy: 0.9721\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 2s 924us/step - loss: 0.0862 - accuracy: 0.9708 - val_loss: 0.1094 - val_accuracy: 0.9721\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 2s 944us/step - loss: 0.0837 - accuracy: 0.9719 - val_loss: 0.1108 - val_accuracy: 0.9720\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 2s 916us/step - loss: 0.0858 - accuracy: 0.9711 - val_loss: 0.1095 - val_accuracy: 0.9719\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0849 - accuracy: 0.9713 - val_loss: 0.1179 - val_accuracy: 0.9718\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 2s 923us/step - loss: 0.0846 - accuracy: 0.9713 - val_loss: 0.1144 - val_accuracy: 0.9714\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 2s 899us/step - loss: 0.0804 - accuracy: 0.9735 - val_loss: 0.1142 - val_accuracy: 0.9714\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 2s 932us/step - loss: 0.0840 - accuracy: 0.9714 - val_loss: 0.1117 - val_accuracy: 0.9712\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0806 - accuracy: 0.9726 - val_loss: 0.1143 - val_accuracy: 0.9700\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 2s 943us/step - loss: 0.0815 - accuracy: 0.9732 - val_loss: 0.1155 - val_accuracy: 0.9703\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 2s 947us/step - loss: 0.0805 - accuracy: 0.9732 - val_loss: 0.1142 - val_accuracy: 0.9707\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 2s 961us/step - loss: 0.0811 - accuracy: 0.9721 - val_loss: 0.1139 - val_accuracy: 0.9718\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 2s 913us/step - loss: 0.0787 - accuracy: 0.9740 - val_loss: 0.1146 - val_accuracy: 0.9717\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 2s 953us/step - loss: 0.0792 - accuracy: 0.9737 - val_loss: 0.1125 - val_accuracy: 0.9738\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0792 - accuracy: 0.9733 - val_loss: 0.1169 - val_accuracy: 0.9716\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 2s 955us/step - loss: 0.0762 - accuracy: 0.9743 - val_loss: 0.1177 - val_accuracy: 0.9709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f126c12e5e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test), callbacks=cbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-threat",
   "metadata": {},
   "source": [
    "## Pequeña adaptacion para que la forma de imagenes y salida sea identica a la que tendría si se cargasen con el codigo propio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "periodic-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_tr, y_tr), (x_te, y_te) = mnist.load_data()\n",
    "x_tr, x_te = x_tr / 255.0, x_te / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-ballot",
   "metadata": {},
   "source": [
    "### Como despues se tienen que leer del disco, esto hara que las imagenes tengan 3 canales de color (aunque los 3 sean idénticos)\n",
    "### Por tanto, replicar 3 canales de colorplt.imshow(np.stack([x_tr, x_tr, x_tr], axis=-1)[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decreased-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_tr = np.stack([x_tr, x_tr, x_tr], axis=-1)\n",
    "x_te = np.stack([x_te, x_te, x_te], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "preliminary-birmingham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-questionnaire",
   "metadata": {},
   "source": [
    "### Al usar el otro código, las etiquetas serán 'one-hot', convertir éstas también a ese formato, y utilizar 'categorical_crossentropy' en lugar de 'sparse_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "separated-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = tf.keras.utils.to_categorical(y_tr, num_classes=10)\n",
    "y_te = tf.keras.utils.to_categorical(y_te, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cutting-nashville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "developed-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28, 3)),\n",
    "  tf.keras.layers.Dense(48, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "freelance-supervision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "cbacks = [tf.keras.callbacks.TensorBoard('logs/MNIST_2', histogram_freq=1, write_graph=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "artificial-relevance",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.5886 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0038s vs `on_train_batch_end` time: 0.0169s). Check your callbacks.\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3740 - accuracy: 0.8868 - val_loss: 0.1717 - val_accuracy: 0.9484\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2345 - accuracy: 0.9287 - val_loss: 0.1334 - val_accuracy: 0.9597\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2016 - accuracy: 0.9377 - val_loss: 0.1322 - val_accuracy: 0.9605\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1862 - accuracy: 0.9426 - val_loss: 0.1105 - val_accuracy: 0.9642\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1758 - accuracy: 0.9461 - val_loss: 0.1146 - val_accuracy: 0.9638\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1641 - accuracy: 0.9483 - val_loss: 0.1053 - val_accuracy: 0.9657\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1547 - accuracy: 0.9513 - val_loss: 0.1041 - val_accuracy: 0.9687\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 2s 996us/step - loss: 0.1500 - accuracy: 0.9524 - val_loss: 0.1057 - val_accuracy: 0.9692\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 2s 997us/step - loss: 0.1469 - accuracy: 0.9523 - val_loss: 0.1086 - val_accuracy: 0.9682\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1424 - accuracy: 0.9550 - val_loss: 0.1168 - val_accuracy: 0.9677\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1371 - accuracy: 0.9570 - val_loss: 0.1098 - val_accuracy: 0.9702\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1339 - accuracy: 0.9574 - val_loss: 0.1078 - val_accuracy: 0.9683\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1349 - accuracy: 0.9565 - val_loss: 0.1098 - val_accuracy: 0.9693\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1306 - accuracy: 0.9571 - val_loss: 0.1069 - val_accuracy: 0.9702\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1269 - accuracy: 0.9586 - val_loss: 0.1100 - val_accuracy: 0.9699\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 2s 983us/step - loss: 0.1238 - accuracy: 0.9604 - val_loss: 0.1070 - val_accuracy: 0.9715\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1242 - accuracy: 0.9593 - val_loss: 0.1098 - val_accuracy: 0.9722\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1237 - accuracy: 0.9588 - val_loss: 0.1119 - val_accuracy: 0.9725\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1185 - accuracy: 0.9616 - val_loss: 0.1070 - val_accuracy: 0.9701\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1197 - accuracy: 0.9605 - val_loss: 0.1161 - val_accuracy: 0.9690\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 2s 991us/step - loss: 0.1168 - accuracy: 0.9620 - val_loss: 0.1084 - val_accuracy: 0.9712\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 2s 989us/step - loss: 0.1154 - accuracy: 0.9621 - val_loss: 0.1120 - val_accuracy: 0.9704\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 2s 990us/step - loss: 0.1177 - accuracy: 0.9608 - val_loss: 0.1163 - val_accuracy: 0.9690\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 2s 992us/step - loss: 0.1106 - accuracy: 0.9638 - val_loss: 0.1153 - val_accuracy: 0.9710\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1082 - accuracy: 0.9636 - val_loss: 0.1219 - val_accuracy: 0.9701\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1093 - accuracy: 0.9640 - val_loss: 0.1238 - val_accuracy: 0.9715\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1073 - accuracy: 0.9646 - val_loss: 0.1210 - val_accuracy: 0.9716\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1070 - accuracy: 0.9641 - val_loss: 0.1178 - val_accuracy: 0.9701\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 2s 962us/step - loss: 0.1060 - accuracy: 0.9646 - val_loss: 0.1161 - val_accuracy: 0.9700\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 2s 975us/step - loss: 0.1049 - accuracy: 0.9648 - val_loss: 0.1193 - val_accuracy: 0.9712\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 2s 979us/step - loss: 0.1065 - accuracy: 0.9641 - val_loss: 0.1171 - val_accuracy: 0.9694\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 2s 998us/step - loss: 0.1025 - accuracy: 0.9658 - val_loss: 0.1218 - val_accuracy: 0.9693\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1039 - accuracy: 0.9656 - val_loss: 0.1234 - val_accuracy: 0.9698\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1002 - accuracy: 0.9660 - val_loss: 0.1234 - val_accuracy: 0.9710\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1017 - accuracy: 0.9655 - val_loss: 0.1240 - val_accuracy: 0.9703\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1007 - accuracy: 0.9670 - val_loss: 0.1222 - val_accuracy: 0.9694\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1027 - accuracy: 0.9653 - val_loss: 0.1265 - val_accuracy: 0.9688\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0965 - accuracy: 0.9677 - val_loss: 0.1273 - val_accuracy: 0.9718\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0999 - accuracy: 0.9668 - val_loss: 0.1315 - val_accuracy: 0.9714\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 2s 988us/step - loss: 0.0982 - accuracy: 0.9671 - val_loss: 0.1240 - val_accuracy: 0.9719\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1001 - accuracy: 0.9667 - val_loss: 0.1236 - val_accuracy: 0.9708\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0967 - accuracy: 0.9679 - val_loss: 0.1259 - val_accuracy: 0.9717\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 2s 985us/step - loss: 0.0965 - accuracy: 0.9676 - val_loss: 0.1288 - val_accuracy: 0.9696\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0929 - accuracy: 0.9685 - val_loss: 0.1339 - val_accuracy: 0.9704\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 2s 979us/step - loss: 0.0960 - accuracy: 0.9681 - val_loss: 0.1343 - val_accuracy: 0.9704\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 2s 996us/step - loss: 0.0927 - accuracy: 0.9684 - val_loss: 0.1492 - val_accuracy: 0.9688\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0934 - accuracy: 0.9688 - val_loss: 0.1315 - val_accuracy: 0.9689\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 2s 1000us/step - loss: 0.0948 - accuracy: 0.9681 - val_loss: 0.1387 - val_accuracy: 0.9701\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0930 - accuracy: 0.9690 - val_loss: 0.1411 - val_accuracy: 0.9683\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0943 - accuracy: 0.9689 - val_loss: 0.1438 - val_accuracy: 0.9696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f121871c670>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_tr, y_tr, epochs=50, validation_data=(x_te, y_te), callbacks=cbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit6c4dec2e42734bc298ce0c3bfcfccb75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
