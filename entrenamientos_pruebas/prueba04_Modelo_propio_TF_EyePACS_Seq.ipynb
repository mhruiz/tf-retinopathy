{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hungarian-incident",
   "metadata": {},
   "source": [
    "# Codigo propio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infectious-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.custom_metrics as metrics\n",
    "import lib.evaluation as ev\n",
    "import lib.plotting as plot\n",
    "import lib.models as models\n",
    "import lib.dataset as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "governing-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abroad-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_LEVELS_PER_CLASS = [[0], [1,2,3,4]]\n",
    "\n",
    "IMAGE_SIZE = (540, 540, 3)\n",
    "\n",
    "# Specify dataset files\n",
    "TRAIN_FILE = 'DATASET-VALIDATION-10.csv'\n",
    "VALIDATION_FILE = 'DATASET-VALIDATION-10.csv'\n",
    "\n",
    "TRAINING_BATCH_SIZE = 32\n",
    "TRAINING_DATA_AUG = False\n",
    "TRAINING_BALANCED = False\n",
    "TRAINING_SHUFFLE = False\n",
    "TRAINING_PREFETCH = None\n",
    "TRAINING_TAKE_SIZE = None\n",
    "\n",
    "VALIDATION_BATCH_SIZE = 32\n",
    "VALIDATION_DATA_AUG = False\n",
    "VALIDATION_BALANCED = False\n",
    "VALIDATION_SHUFFLE = False\n",
    "VALIDATION_PREFETCH = None\n",
    "VALIDATION_TAKE_SIZE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "encouraging-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dt)\n",
    "\n",
    "'''\n",
    "def create_dataset_new(csv_file, \n",
    "                        list_list_classes,\n",
    "                        balanced=False,\n",
    "                        apply_data_augmentation=False,\n",
    "                        batch_size=1, \n",
    "                        prefetch_buffer=None, \n",
    "                        shuffle=False,\n",
    "                        size=None):\n",
    "'''\n",
    "\n",
    "train_dataset, y_true_train = dt.create_dataset_new(TRAIN_FILE, \n",
    "                                                    DR_LEVELS_PER_CLASS, \n",
    "                                                    balanced=TRAINING_BALANCED, \n",
    "                                                    apply_data_augmentation=TRAINING_DATA_AUG, \n",
    "                                                    batch_size=TRAINING_BATCH_SIZE, \n",
    "                                                    prefetch_buffer=TRAINING_PREFETCH, \n",
    "                                                    shuffle=TRAINING_SHUFFLE,\n",
    "                                                    size=TRAINING_TAKE_SIZE)\n",
    "\n",
    "val_dataset, y_true_val = dt.create_dataset_new(VALIDATION_FILE, \n",
    "                                                DR_LEVELS_PER_CLASS, \n",
    "                                                balanced=VALIDATION_BALANCED,\n",
    "                                                apply_data_augmentation=VALIDATION_DATA_AUG,\n",
    "                                                batch_size=VALIDATION_BATCH_SIZE,\n",
    "                                                prefetch_buffer=VALIDATION_PREFETCH, \n",
    "                                                shuffle=VALIDATION_SHUFFLE, \n",
    "                                                size=VALIDATION_TAKE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "infectious-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(5,5), strides=2, input_shape=IMAGE_SIZE),\n",
    "    tf.keras.layers.ReLU(), # 270, 270\n",
    "    tf.keras.layers.Conv2D(32,(7,7), strides=5),\n",
    "    tf.keras.layers.ReLU(), # 54, 54\n",
    "    tf.keras.layers.Conv2D(32,(3,3), strides=2),\n",
    "    tf.keras.layers.ReLU(), # 27, 27\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(48, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(len(DR_LEVELS_PER_CLASS), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behavioral-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "cbacks = [tf.keras.callbacks.TensorBoard('logs/EYEPACS_Seq_Modelo_propio (sin Drop)', histogram_freq=1, write_graph=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dress-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2790), started 23:58:53 ago. (Use '!kill 2790' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4819b934e9cad34e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4819b934e9cad34e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See Tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "proof-sunday",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/222 [..............................] - ETA: 0s - loss: 0.6969 - accuracy: 0.4062WARNING:tensorflow:From /home/alumno/miguel_herrera/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "222/222 [==============================] - 27s 120ms/step - loss: 0.5779 - accuracy: 0.7431 - val_loss: 0.5745 - val_accuracy: 0.7467\n",
      "Epoch 2/50\n",
      "222/222 [==============================] - 27s 120ms/step - loss: 0.5633 - accuracy: 0.7467 - val_loss: 0.5663 - val_accuracy: 0.7467\n",
      "Epoch 3/50\n",
      "222/222 [==============================] - 26s 119ms/step - loss: 0.5608 - accuracy: 0.7467 - val_loss: 0.5622 - val_accuracy: 0.7467\n",
      "Epoch 4/50\n",
      "222/222 [==============================] - 26s 119ms/step - loss: 0.5574 - accuracy: 0.7467 - val_loss: 0.5552 - val_accuracy: 0.7467\n",
      "Epoch 5/50\n",
      "222/222 [==============================] - 26s 119ms/step - loss: 0.5528 - accuracy: 0.7467 - val_loss: 0.5516 - val_accuracy: 0.7467\n",
      "Epoch 6/50\n",
      "222/222 [==============================] - 26s 118ms/step - loss: 0.5490 - accuracy: 0.7467 - val_loss: 0.5499 - val_accuracy: 0.7467\n",
      "Epoch 7/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.5456 - accuracy: 0.7467 - val_loss: 0.5428 - val_accuracy: 0.7467\n",
      "Epoch 8/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5387 - accuracy: 0.7467 - val_loss: 0.5422 - val_accuracy: 0.7467\n",
      "Epoch 9/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.5382 - accuracy: 0.7467 - val_loss: 0.5338 - val_accuracy: 0.7467\n",
      "Epoch 10/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5303 - accuracy: 0.7477 - val_loss: 0.5275 - val_accuracy: 0.7467\n",
      "Epoch 11/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5280 - accuracy: 0.7467 - val_loss: 0.5278 - val_accuracy: 0.7463\n",
      "Epoch 12/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.5203 - accuracy: 0.7470 - val_loss: 0.5179 - val_accuracy: 0.7470\n",
      "Epoch 13/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.5171 - accuracy: 0.7488 - val_loss: 0.5179 - val_accuracy: 0.7479\n",
      "Epoch 14/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.5084 - accuracy: 0.7490 - val_loss: 0.5048 - val_accuracy: 0.7490\n",
      "Epoch 15/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.4956 - accuracy: 0.7528 - val_loss: 0.5151 - val_accuracy: 0.7493\n",
      "Epoch 16/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.4841 - accuracy: 0.7605 - val_loss: 0.5121 - val_accuracy: 0.7619\n",
      "Epoch 17/50\n",
      "222/222 [==============================] - 25s 114ms/step - loss: 0.4755 - accuracy: 0.7683 - val_loss: 0.4797 - val_accuracy: 0.7704\n",
      "Epoch 18/50\n",
      "222/222 [==============================] - 25s 114ms/step - loss: 0.4508 - accuracy: 0.7881 - val_loss: 0.4736 - val_accuracy: 0.7750\n",
      "Epoch 19/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.4341 - accuracy: 0.7894 - val_loss: 0.4762 - val_accuracy: 0.7746\n",
      "Epoch 20/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.4130 - accuracy: 0.8097 - val_loss: 0.4521 - val_accuracy: 0.7937\n",
      "Epoch 21/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.3814 - accuracy: 0.8198 - val_loss: 0.4312 - val_accuracy: 0.8016\n",
      "Epoch 22/50\n",
      "222/222 [==============================] - 25s 114ms/step - loss: 0.3613 - accuracy: 0.8267 - val_loss: 0.4312 - val_accuracy: 0.7961\n",
      "Epoch 23/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.3594 - accuracy: 0.8363 - val_loss: 0.4239 - val_accuracy: 0.8036\n",
      "Epoch 24/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.3270 - accuracy: 0.8480 - val_loss: 0.3961 - val_accuracy: 0.8175\n",
      "Epoch 25/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.3095 - accuracy: 0.8594 - val_loss: 0.3532 - val_accuracy: 0.8363\n",
      "Epoch 26/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.2909 - accuracy: 0.8717 - val_loss: 0.3768 - val_accuracy: 0.8160\n",
      "Epoch 27/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.2761 - accuracy: 0.8805 - val_loss: 0.3350 - val_accuracy: 0.8447\n",
      "Epoch 28/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.2428 - accuracy: 0.8898 - val_loss: 0.3782 - val_accuracy: 0.7746\n",
      "Epoch 29/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.2161 - accuracy: 0.8988 - val_loss: 0.3740 - val_accuracy: 0.7752\n",
      "Epoch 30/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.2428 - accuracy: 0.8913 - val_loss: 0.3381 - val_accuracy: 0.8128\n",
      "Epoch 31/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.2001 - accuracy: 0.9086 - val_loss: 0.3366 - val_accuracy: 0.8118\n",
      "Epoch 32/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.1911 - accuracy: 0.9160 - val_loss: 0.3015 - val_accuracy: 0.8553\n",
      "Epoch 33/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.1711 - accuracy: 0.9290 - val_loss: 0.2727 - val_accuracy: 0.8726\n",
      "Epoch 34/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.1404 - accuracy: 0.9414 - val_loss: 0.3043 - val_accuracy: 0.8503\n",
      "Epoch 35/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.1305 - accuracy: 0.9410 - val_loss: 0.2953 - val_accuracy: 0.8430\n",
      "Epoch 36/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.1113 - accuracy: 0.9507 - val_loss: 0.2756 - val_accuracy: 0.8432\n",
      "Epoch 37/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.0995 - accuracy: 0.9590 - val_loss: 0.3250 - val_accuracy: 0.8427\n",
      "Epoch 38/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.0950 - accuracy: 0.9603 - val_loss: 0.2909 - val_accuracy: 0.8643\n",
      "Epoch 39/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.0865 - accuracy: 0.9634 - val_loss: 0.4468 - val_accuracy: 0.8253\n",
      "Epoch 40/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.0910 - accuracy: 0.9610 - val_loss: 0.2551 - val_accuracy: 0.8857\n",
      "Epoch 41/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.0801 - accuracy: 0.9672 - val_loss: 0.2800 - val_accuracy: 0.8909\n",
      "Epoch 42/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.0796 - accuracy: 0.9679 - val_loss: 0.2686 - val_accuracy: 0.8877\n",
      "Epoch 43/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.0712 - accuracy: 0.9725 - val_loss: 0.2446 - val_accuracy: 0.9143\n",
      "Epoch 44/50\n",
      "222/222 [==============================] - 26s 115ms/step - loss: 0.0696 - accuracy: 0.9723 - val_loss: 0.2685 - val_accuracy: 0.9161\n",
      "Epoch 45/50\n",
      "222/222 [==============================] - 25s 115ms/step - loss: 0.0647 - accuracy: 0.9742 - val_loss: 0.2619 - val_accuracy: 0.9034\n",
      "Epoch 46/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.0755 - accuracy: 0.9718 - val_loss: 0.2511 - val_accuracy: 0.9196\n",
      "Epoch 47/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.0830 - accuracy: 0.9738 - val_loss: 0.2396 - val_accuracy: 0.9093\n",
      "Epoch 48/50\n",
      "222/222 [==============================] - 26s 117ms/step - loss: 0.0618 - accuracy: 0.9780 - val_loss: 0.2317 - val_accuracy: 0.9244\n",
      "Epoch 49/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.0548 - accuracy: 0.9796 - val_loss: 0.2215 - val_accuracy: 0.9295\n",
      "Epoch 50/50\n",
      "222/222 [==============================] - 26s 116ms/step - loss: 0.0479 - accuracy: 0.9818 - val_loss: 0.1972 - val_accuracy: 0.9264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fac88ec86a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=50, validation_data=val_dataset, verbose=1, callbacks=cbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "institutional-electric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7103\n",
      "7103\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "paths = pd.read_csv('DATASET-VALIDATION-10.csv')['path'].tolist()\n",
    "print(len(paths))\n",
    "\n",
    "paths_set = set()\n",
    "paths_set.update(paths)\n",
    "print(len(paths_set))\n",
    "\n",
    "# Son 7.103 rutas de imágenes únicas, no hay repeticiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit6c4dec2e42734bc298ce0c3bfcfccb75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
